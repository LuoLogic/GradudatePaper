%英文摘要，自行编辑内容




\chapter{ABSTRACT}
\xiaosi

Nowadays, deep learning technology has shown its application potential in many fields, and in the field of image classification, with the increasing complexity of the model structure and the gradual increase in the number of parameters, it is difficult to give reliable explanations for the classification results given by image classification models. The saliency map interpretation technique, as an emerging branch of deep learning interpretable work, aims to find the basis for the image classification model to make decisions from the input images, so as to give a visual interpretation. However, the current saliency map interpretation techniques generally have the defects of generating original saliency maps with low resolution and being unable to accurately locate the key features of the target. Therefore, in this thesis, we focus on the defects of the current saliency map interpretation technology to study how to improve the resolution of the saliency map, increase the effective information presented by the saliency map, and improve the ability of the saliency map to explain the visualization of the decision-making results of the image classification neural network. The main work of this thesis is as follows:

First, this thesis proposes a saliency map interpretation method for image classification model based on convolutional neural network. The method obtains a collection of feature maps with different resolutions from the last convolutional layer of the image classification neural network by zooming the original input image at multiple scales and inputting them into the image classification model separately. The gradient matrix corresponding to the feature maps of the last convolutional layer is obtained by backpropagating the scores of the target categories respectively. Then the different resolution feature maps and the gradient matrix are fused into the discriminant of the original input image and weighted to obtain the mask. All the masks are perturbed to the original input image and input to the image classification model to get the probability scores of the target categories as the weights of the masks. Finally, all the masks and their corresponding probability scores are weighted and multiplied to obtain the final saliency map. Qualitative and quantitative experiments on three publicly available datasets (ILSVRC 2012 dataset, PASCAL VOC dataset, and COCO 2014 dataset) show that the saliency maps generated by this method have higher resolution and can more accurately find out the decision basis of the neural network for image classification in the input images, and provide more intuitive visual interpretation of the results.


Second, in response to the generally low resolution of the original saliency maps generated by current saliency map interpretation methods, this thesis proposes a generalized saliency map enhancement method that can be directly applied to most saliency map interpretation methods. The method uses a fixed-size sliding window to up-sample all local regions in the input image to the input image size, and then inputs the results to the selected saliency map interpretation method to obtain category-specific saliency maps and probability scores for all images, and finally down-samples the saliency maps to the window at the corresponding position of the input image and multiplies them by the probability scores, which results in saliency maps with more details. In this thesis, the method is applied to different saliency map interpretation methods, and both quantitative indexes and intuitive evaluation show that the method significantly improves the quality of the saliency maps generated by other saliency map interpretation methods, thus proving the effectiveness and reliability of the method.

Finally, for the current existence of many saliency map generation methods to achieve complexity, it is difficult to intuitively compare the quality of saliency maps generated by different methods of the problem, this thesis designs and implements a saliency map interpretation method comparison evaluation system.
\\

\noindent\textbf{Keywords：} 
\begin{minipage}[t]{0.85\linewidth}
	Image classification neural networks, Deep learning interpretability, Saliency maps, Class activation mapping
\end{minipage}

\clearpage